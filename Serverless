Introduction to Serverless

 - Serverless is a new paradign in which the developers don't have to manage servers anymore
 - They just deploy code (functions)
 - Initially Serverless == FaaS (Function as a Service)
 - Serverless was poineered by AWS Lambda but now also includes anything that is not managed by the user:
    1. Databases
    2. Storage
    3. Messaging
    4. etc...
 - Serverless does not mean that there are no servers, it means you don't manage and provision/see them

 - Serverless in AWS:
 - We have our users, that for example, would get static content from our S3 bucket (delivered as a website)
 - Then, we would login with Amazon Cognito, where our users would have their identity stored
 - This would invoke your REST API via Amazon API Gateway
 - The API Gateway would invoke your Lambda functions
 - The Lambda functions would invoke your DynamoDB

 - Serverless services in AWS are:
    1. AWS Lambda
    2. DynamoDB
    3. AWS Cognito
    4. AWS API Gateway
    5. Amazon S3
    6. SNS & SQS
    7. Kinesis Data Firehose
    8. Aurora Serverless
    9. Step Functions
    10. Fargate

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

AWS Lambda

 - AWS Lambda are Virtual Functions (no servers to manage!)
 - Limited by time (short executions)
 - They run on-demand (only run when invoked)
 - Scaling is automated

 - Benefits of AWS Lambda:
 - Easy pricing:
    1. Pay per request and compute time
    2. Free tier of 1,000,000 Lambda requests and 400,000 GBs of compute time
 - Integrated with the whole AWS suite of services
 - Integrated with many programming languages
 - Easy monitoring through AWS CloudWatch
 - Easy to get more resources per functions (up to 10GB of RAM)
 - Increasing RAM will also improve CPU and network

 - AWS Lambda language support:
 - Node,js (JavaScript)
 - Python
 - Java (java 8 compatible)
 - C# (.NET Core)
 - Golang
 - C# / Powershell
 - Ruby
 - Custom Runtime API (community supported, e.g. Rust)

 - Lambda container image:
    1. The container image must implement the Lambda Runtime API
    2. ECS / Fargate is preferred for running arbitraru Docker images

 - AWS Lambda Integrations:
 - Main ones:
    1. API Gateway (create REST API and invoke functions)
    2. Kinesis (uses Lambda to do data transformations on the fly)
    3. DynamoDB (used to create triggers for Lambda functions upon DB event)
    4. S3 (Lambda function triggers whenever a change is made in S3)
    5. CloudFront (Lambda at edge locations)
    6. CloudWatch Events EventBridge (whenever something happens in the infrastructure and we want to react to it with a Lambda function)
    7. CloudWatch Logs (to stream logs whenever you want with Lambda)
    8. SNS (to react to notifications and SNS topics with Lambda)
    9. SQS (to process messages from your queue with Lambda)
    10. Cognito (react to whenever a user logs in, e.g. to a DB)
 - With Lambda, you can have an Automated and fully Reactive architecture
 - Example: Serverless CRON job
 - You can make an EventBridge rule that triggers every hour and invokes the Lambda Function to perform a task

 - AWS Lambda Pricing:
 - You can find overalll pricing information here: https://aws.amazon.com/lambda/pricing
 - Pay per calls:
    1. First 1,000,000 requests are free
    2. $0.20 per 1 million requests thereafter ($0.0000002 per request)
 - Pay per duration: (in increment of 1 ms) 
    1. 400,000 GB-seconds of compute time per month if FREE
    2. == 400,000 seconds if function is 1 GB RAM
    3. == 3,200,000 seconds if function is 128 MB RAM
    4. After that $1.00 for 600,000 GB-seconds
 - It is usually very cheap to run AWS Lambda, so it is very popular


 - AWS Lambda Limits to know - per region
 - Execution:
    1. Memory allocation: 128 MB - 10 GB (1 MB increments)
    2. Maximum execution time: 900 seconds (15 minutes)
    3. Environment variables (4 KB)
    4. Disk capacity in the "function container" (in /tmp): 512 MB to 10 GB
    5. Concurrency executions: 1000 (can be increased)

 - Deployment:
    1. Lambda function deployment siza (compressed .zip): 50 MB
    2. Size of uncompressed deployment (code + dependencies): 250 MB
    3. Can use the /tmp directory to load other files at startup
    4. Size of environment variables: 4 KB


 - Lambda SnapStart:
 - Improves your Lambda functions performance up to 10x at no extra cost for Java 11 and above
 - Lambda invocation has lifecycle phases
 - Ususally Lambda works as follows:
   Init --> Invoke --> Shutdown
 - When SnapStart is enabled, function is invoked from a pre-initialized state (skips Init phase)
 - When you publish a new version:
    1. Lambda initializes the function
    2. Lambda takes a snapshot of memory and disk state of the initialized function
    3. Snapshot is cached for low-latency access (hence why it's called SnapStart)


 - Customization at the Edge:
 - Many modern applications execute some form of the logic at the edge
 - This is called Edge Functions:
    1. A code that you write and attach to CloudFront distributions
    2. Runs close to your users to minimize latency
 - CloudFront provides two types: CloudFront Functions & Lambda@Edge
 - You don't have to manage any servers
 - Functions are deployed globally
 - Use cases: 
    1. Customize the CDN content
    2. Website Security and Privacy
    3. Dynamic Web Application at the Edge
    4. Search Engine Optimization (SEO)
    5. Intelligently route across origins and data centers
    6. Bot mitigation at the edge
    7. Real-time image transformation
    8. A/B testing
    9. User authentication and authorization
    10. User prioritization
    11. User tracking and analytics
 - Pay only for what you use
 - Fully serverless

 - CloudFront Functions:
 - CloudFront functions are lightweight and written in JavaScript
 - Used for high-scale, latency-sensitive CDN customizations
 - Sub-MS startup times, millions of requests per second
 - Diagram of how requests and responses work:

   Client ---(Viewer Request)---> CloudFront ---(Origin Request)---> Origin ---(Origin Response)---> CloudFront ---(Viewer Response)---> Client

 - Used to change Viewer requests and responses:
    1. Viewer requests: after CloudFront receives a request from a viewer
    2. Viewer response: before CloudFront forwards the response to the viewer
 - Native feature of CloudFront (manage code entirely with CloudFront)

 - Lambda@Edge:
 - Lambda functions written in NodeJS or Python
 - Scales to 1000s of requests per second
 - Used to change CloudFront requests and responses:
    1. Viewe Request - after CloudFront receives a request from a viewer
    2. Origin Request - Before CloudFront forwards the request to the origin
    3. Origin Response - after CloudFront receives the response from the origin
    4. Viewer Response - before CloudFront forwards the response to the viewer
 - Author your functions in one AWS Region (us-east-1), then CloudFront replicates to its locations

 - CloudFront Functions vs. Lambda@Edge
 - CloudFront functions:
    1. Runtime support - JavaScript
    2. # of requests - Millions of requests per second
    3. CloudFront Triggers - Viewer Request/Response
    4. Max. Execution time - < 1 ms
    5. Max. Memory - 2 MB
    6. Total Package Size - 10 KB
    7. Network Access, File System Access - No
    8. Access to the request body - No
    9. Pricing - Free tier available, 1/6th the price of @Edge

 - Lambda@Edge:
    1. Runtime support - NodeJS, Python
    2. # of requests - Thousands of request per second
    3. CloudFront Triggers - Viewer request/response, Origin request/response
    4. Max. Execution time - 5-10 seconds
    5. Max. Memory - 128 MB up to 10 GB
    6. Total Package Size - 1 MB - 50 MB
    7. Network Access, File System Access - Yes
    8. Access to the request body - Yes
    9. Pricing - No free tier, charged per request & duration

 - CloudFront Functions vs. Lambda@Edge - Use Cases
 - CloudFront Functions:
    1. Cache key normalization:
       - Transform request attributes (headers, cookies, query strings, URL) to create an optimal Cache key
    2. Header manipulation:
       - Insert/modify/delete HTTP headers in the request or response
    3. URL rewrites or redirects
    4. Request authentication & authorization:
       - Create and validate user-generated tokens (e.g. JWT) to allow/deny requests

 - Lambda@Edge:
    1. Longer execution time (several ms)
    2. Adjustable CPU or memory
    3. Your code depends on 3rd party libraries (e.g. AWS SDK to access other AWS services)
    4. Network access to use external services for processing
    5. File system access or access to the body of HTTP requests

 - Lambda in VPC:
 - By default, your Lambda function is launched outside of your own VPC (in AWS-owned VPC)
 - Therefore, it cannot access resources in VPC (RDS, ElastiCache, internal ELB, etc...)
 - You can launch your Lambda function inside your VPC
 - You must define the VPC ID, the Subnets and the Security Groups
 - Lambda will create an ENI (Elastic Network Interface) in your subnets
 - Lambda with RDS Proxy
 - If Lambda functions directly access your database, they may open too many connections under high load
 - RDS Proxy:
    1. Improve scalability by pooling and sharing DB connections
    2. Improve availability by reducing 66% of the failover time and preserving connections
    3. Improve security by enforcing IAM authentication and storing credentials in Secrets Manager
 - The Lambda function must be deployed in your VPC, because RDS Proxy is never publicly accessible


 - Invoking Lambda from RDS & Aurora:
 - Invoke Lambda functions from within your DB instance
 - Allows you to process data events from within a database
 - Supported by RDS for PostgreSQL and Aurora MySQL
 - Must allow outbound traffic to your Lambda function from within your DB instance (Public, NAT GW, VPC Endpoints)
 - DB instance must have the required permissions to invoke the Lambda function (Lambda Resource-based Policy & IAM Policy)
 - Diagram:

   User ---(register(INSERT))---> RDS DB Instance(with permissions) ---(invoke)---> Lambda function ---(send Email)---> Amazon SES ---(route mail)---> User


 - RDS Event notifications:
 - Notifications that tell information about the DB instance itself (created, stopped, start, etc...)
 - You don't have any information about the data itself
 - Subscribe to the following event categories:
    1. DB instance
    2. DB snapshot
    3. DB parameter group
    4. DB Security group
    5. RDS Proxy
    6. Custom Engine Version
 - Near real-time events (up to 5 mins)
 - Send notifications to SNS or subscribe to events using EventBridge


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Amazon DynamoDB

 - Fully managed, highly available with replication across multiple AZs
 - NoSQL database - not a relational database - has transaction support
 - Scales to massive workloads, distributed database
 - Millions of requests per seconds, trillions of rows, 100s of TB of storage
 - Fast and consistent in performance (single-digit millisecond)
 - Integrated with IAM for security, authorization and administration
 - Low cost and auto-scaling capabilities
 - No maintenance or patching, always available
 - Standard & Infrequent Access (IA) table class

 - DynamoDB - Basics:
 - DynamoDB is made of Tables
 - Each table has a Primary Key (must be decided at creation time)
 - Each table can have an infinite number of items (= rows)
 - Each item has attributes (can be added over time - can be null)
 - You can add attributes overtime (without having to add columns like in a relational DB)
 - Maximum size of an item is 400KB
 - Data types supported are:
    1. Scalar Types - String, Number, Binary, Boolean, Null
    2. Document types - List, Map
    3. Set Types - String Set, Number Set, Binary Set
 - Therefore, in DynamoDB you can have rapidly evolving schemas
 - DB structure is made up of:
    1. Primary key, which includes:
       - Partition Key
       - Sort Key
    2. Attributes

 - DynamoDB - Read/Write Capacity Modes:
 - Control how you manage your table's capacity (read/write throughput)
 - Provisioned Mode (default):
    1. You specify the number of reads/writes per second
    2. You need to plan capacity beforehand
    3. Pay for provisioned Read Capacity Units (RCU) & Write Capacity Units (WCU)
    4. Possibility to add auto-scaling mode for RCU & WCU
 - On-Demand mode:
    1. Read/writes automatically scale up/down with your workloads
    2. No capacity planning needed
    3. Pay for what you use (more expensinve)
    4. Great for unpredictable workloads, steep sudden spikes


 - DynamoDB Accelerator (DAX):
 - Fully-managed, highly available, seamless in-memory cache for DynamoDB
 - Help solve read congestion by caching
 - Microseconds latency for cached data
 - Doesn't require application logic modification (compatible with existing DynamoDB APIs)
 - 5 minutes TTL for cache (default)
 - You essentially create a DAX cluster made of a few cache nodes
 - You connect to the DAX cluster, which in turn is connected to the DynamoDB
 - Diagram:

   Application ------> DAX Cluster(made of several cache nodes) ------> Amazon DynamoDB

 - Why you would use DAX instead of ElastiCache
 - DAX is in front of DynamoDB and is helpful for individual objects cache + queries and scan cache
 - ElastiCache is better for storing aggregation results

 - DynamoDB - Stream Processing:
 - Ordered stream of item-level modifications (create/update/delete) in a table
 - Use cases:
    1. React to changes in real-time (welcome email to users)
    2. Real-time usage analytics
    3. Insert into derivative tables
    4. Implement cross-region replication
    5. Invoke AWS Lambda on changes to your DynamoDB table

 - DynamoDB Streams:
 - 24 hours retention
 - Limited # of consumers
 - Process using AWS Lambda Triggers, or DynamoDB Stream Kinesis adapter

 - Kinesis Data Streams (newer):
 - 1 year retention
 - High number of consumers
 - Process using AWS Lambda, Kinesis Data Analytics, Kinesis Data Firehose, AWS Glue Streaming ETL...

 - DynamoDB Streams diagram:
                                                                                                                        |---(messaging, notifications)---> Amazon SNS
   Application ---(create/update/delete)---> DynamoDB Table ------> Processing layer (DynamoDB KCL Adapter or Lambda) --| 
                                                                                                                        |---(filtering. transforming )---> DynamoDB Table       
 - Kinesis Data Streams diagram:
                                                                                                                          |---(analytics)---> Amazon Redshift
   Application ---(create/update/delete)---> DynamoDB Table ------> Kinesis Data Streams ------> Kinesis Data Firehose  --|---(archiving)---> Amazon S3
                                                                                                                          |---(indexing)--->Amazon OpenSearch

 - DynamoDB Global Tables:
 - A table that can be replicated in multiple regions
 - Two-way replication between tables
 - The goal is to make DynamoDB table accessible with low latency in multiple regions
 - Active-Active replication
 - Applications can Read and Write to the table in any region
 - Must enable DynamoDB Streams as a pre-requisite

 - DynamoDB - Time To Live (TTL):
 - Automatically delete items after an expiry timestamp
 - TTL is contained in the SessionData (Table)
 - Attributes for the SessionData are:
    1. User_ID
    2. Session_ID
    3. ExpTime (TTL)
 - ExpTime has a timestamp in it
 - Once the current time passes the timestamp, the item gets deleted
 - Use cases:
    1. Reduce stored data by keeping only current items
    2. Adhere to regulatori obligations
    3. Web session handling (important for exam)

 - DynamoDB - Backups for disaster recovery
 - Continuous backups using point-in-time recovery (PITR):
    1. Optionally enabled for the last 35 days
    2. Point-in-time recovery to any time within the backup window
    3. The recovery process creates a new table
 - On-demand backups:
    1. Full backups for long-term retention, until explicitly deleted
    2. Doesn't affect performance or latency
    3. Can be configured and managed in AWS Backup (enables cross-region copy)
    4. The recovery process creates a new table

 - DynamoDB - Integration with Amazon S3:
 - Export to S3 (must enable PITR):
    1. Works for any point in time in the last 35 days
    2. Doesn't affect the read capacity of your table
    3. Perform data analysis on top of DynamoDB
    4. Retain snapshots for auditing
    5. ETL on top of S3 data before importing back into DynamoDB
    6. Export in DynamoDB JSON or ION format
  - Import from S3:
     1. Import CSV, DynamoDB JSON or ION format
     2. Doesn't consume any write capacity
     3. Creates a new table
     4. Import errors are logged into CloudWatch Logs

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

API Gateway

 - API Gateway Example: Building a Serverless API:

   Client <---(REST API)---> API Gateway <---(Proxy Requests)---> Lambda <---(CRUD)---> DynamoDB

 - AWS API Gateway:
 - AWS Lambda + API Gateway: No infrastructure to manage
 - Support for the WebSocket Protocol
 - Handle API versioning (v1, v2, ...)
 - Handle different environments (dev, test, prod, ...)
 - Handle security (authentication and authorization)
 - Create API keys, handle request throttling
 - Swagger / Open API import to quickly define APIs
 - Transform and validate requests and responses
 - Generate SDK and API specifications
 - Cache API responses

 - API Gateway - Integrations high level:
 - Lambda Function:
    1. Invoke Lambda function
    2. Easy way to expose REST API backed by AWS Lambda
 - HTTP:
    1. Expose HTTP endpoints in the backend
    2. Example: internal HTTP API on premise, Application Load Balancer, ...
    3. Why?: Add rate limiting, caching, user authentications, API keys, etc...
 - AWS Service:
    1. Expose any AWS API through the API Gateway?
    2. Example: start an AWS Step Function workflow, post a message to SQS
    3. Why? Add authentication, deploy publicly, rate control...

 - API Gateway - AWS Service Integration (Kinesis Data Streams) example:
 - We want to have people send data to a Kinesis Data Streams in a secure way, without giving them AWS credentials:

   Client ---(requests)---> API Gateway ---(send)---> Kinesis Data Streams ---(records)---> Kinesis Data Firehose ---(store .json files)---> Amazon S3

 - API Gateway allows us to expose any AWS service to the outside using the API gateway.

 - API Gateway - Endpoint Types:
    1. Edge-optimized (default): For global clients:
       - Requests are routed through the CloudFront Edge locations (improves latency)
       - The API Gateway still lives in only one region
    2. Regional:
       - For clients within the same region
       - Could manually combine with CloudFront (for more control over the caching strategies and the distribution)
    3. Private:
       - Can only be accessed from your VPC using an interface VPC endpoint (ENI)
       - Use a resource policy to define access

 - API Gateway - Security:
 - User Authentication through:
    1. IAM Roles (useful for internal apps)
    2. Cognito (identity for external users - example: mobile users)
    3. Custom Authorizez (your own logic)
 - Custom Domain Name HTTPS security through integration with AWS Certificate Manager (ACM)
    1. If using edge-optimized endpoint, then the certificate must be in us-east-1
    2. If using regional endpoint, the certificate must be in the API gateway region
    1. Must setup a CNAME or A-alias record in Route 53

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

